{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tiny_ImgNet_Custom3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8edSiHPi2N5l",
        "colab_type": "code",
        "outputId": "98cf3ca6-46ee-4d8b-d6ee-b87147c4c09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "#!pip install -q keras\n",
        "import keras\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, GlobalAveragePooling2D,AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.layers.advanced_activations import LeakyReLU, ReLU\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "num_classes = 200\n",
        "epochs = 50\n",
        "l = 10\n",
        "num_filter = 20\n",
        "\n",
        "#layer counter for naming\n",
        "l_count=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuuVjJ0k4EQX",
        "colab_type": "code",
        "outputId": "a6e5a0df-0ed8-4d0d-83ec-afb60d425f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sMtfFSW4HQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/gdrive/My Drive/EIP3/session4/clr_callback.py' clr_callback.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E0VSV-RvbTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from clr_callback import *\n",
        "\n",
        "clr = CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
        "                                step_size=2000., mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztoDypc63gEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def space_to_depth_x2(x):\n",
        "    import tensorflow as tf\n",
        "    return tf.space_to_depth(x, block_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAm6czftF8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#layer counter for naming\n",
        "l_count=0\n",
        "\n",
        "def create_conv_block(x,f_num=16,numlayers=5,maxpool=False,blocknum=1):\n",
        "    # you have used a block of following layers: 32 (same) > 64 (same) > 128 (same) > 256 (same) > 512 (same) > MP\n",
        "    global l_count\n",
        "    l_count=l_count+1\n",
        "    print(x.shape)\n",
        "    for i in range(1,numlayers):\n",
        "      \n",
        "      f_num=f_num*2\n",
        "      #print(blocknum, i,f_num)\n",
        "      x = Conv2D(f_num, (3,3), strides=(1,1), padding='same',name='block_'+str(blocknum)+'_conv_'+str(l_count), use_bias=False)(x)\n",
        "      x = BatchNormalization(name='block_'+str(blocknum)+'_norm_'+str(l_count))(x)\n",
        "      x = ReLU()(x)\n",
        "      l_count=l_count+1\n",
        "    if (maxpool):\n",
        "      x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    \n",
        "    return x\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNnGm8Tv2fR1",
        "colab_type": "code",
        "outputId": "3d0a17ac-ac43-4590-cba1-7e01242ddf24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "input = Input(shape=(None, None, 3))\n",
        "\n",
        "# Block 1\n",
        "block1=create_conv_block(input,32,3,False,1)\n",
        "# Block 2\n",
        "block2=create_conv_block(block1,64,3,False,2)\n",
        "\n",
        "#Block3 \n",
        "block3 = create_conv_block(block2,64,3,False,3)\n",
        "\n",
        "mod_block1=Conv2D(128,1,use_bias=False)(block1)\n",
        "\n",
        "#mod_block3=Conv2D(128,1,use_bias=False)(block3)\n",
        "\n",
        "#concatenate block1_adjusted and block3\n",
        "concat_layer1 = concatenate([mod_block1, block3])\n",
        "\n",
        "if (concat_layer1.shape[1]>=64):\n",
        "  p=3\n",
        "else:\n",
        "  p=2\n",
        "\n",
        "reduce1=MaxPooling2D(pool_size=(p, p))(concat_layer1)\n",
        "\n",
        "#Block4\n",
        "block4=create_conv_block(reduce1,64,4,False,4)\n",
        "\n",
        "\n",
        "\n",
        "#adjust the shape of block 1 to be concatenated to block4\n",
        "#mod_block1=Lambda(space_to_depth_x2)(block1)\n",
        "\n",
        "\n",
        "\n",
        "#Block5\n",
        "block5=create_conv_block(block4,128,4,True,5)\n",
        "\n",
        "block6=create_conv_block(block5,64,4,True,6)\n",
        "\n",
        "#tail1 = Conv2D(num_classes,1,use_bias=False)(block6)\n",
        "\n",
        "\n",
        "\n",
        "#tail2 = Conv2D(num_classes,3,use_bias=False)(tail1)\n",
        "\n",
        "#use average pooling on this 2x2 size output \n",
        "last_layer = Conv2D(num_classes,1,use_bias=False)(block6)\n",
        "\n",
        "# Adjust channels to required numbers and Flatten \n",
        "flat_layer=GlobalAveragePooling2D()(last_layer)\n",
        "#flat_layer = Flatten()(last_layer)\n",
        "\n",
        "#get the output using softmax on this flattened layer \n",
        "\n",
        "output=Activation('softmax')(flat_layer)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, ?, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "(?, ?, ?, 128)\n",
            "(?, ?, ?, 256)\n",
            "(?, ?, ?, 384)\n",
            "(?, ?, ?, 512)\n",
            "(?, ?, ?, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VrRLwpAoQ7l",
        "colab_type": "code",
        "outputId": "060a0a7d-2a37-45cd-f3b3-faf820b3a67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2026
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()\n",
        "\"\"\"\n",
        "#mount drive \n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file=\"/gdrive/My Drive/EIP3/session3/Tiny_ImgNetReLU_Data_Aug_Model.png\")\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block_1_conv_1 (Conv2D)         (None, None, None, 6 1728        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_1_norm_1 (BatchNormalizat (None, None, None, 6 256         block_1_conv_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, None, None, 6 0           block_1_norm_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_1_conv_2 (Conv2D)         (None, None, None, 1 73728       re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_1_norm_2 (BatchNormalizat (None, None, None, 1 512         block_1_conv_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, None, None, 1 0           block_1_norm_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_conv_4 (Conv2D)         (None, None, None, 1 147456      re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_2_norm_4 (BatchNormalizat (None, None, None, 1 512         block_2_conv_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, None, None, 1 0           block_2_norm_4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_2_conv_5 (Conv2D)         (None, None, None, 2 294912      re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_2_norm_5 (BatchNormalizat (None, None, None, 2 1024        block_2_conv_5[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, None, None, 2 0           block_2_norm_5[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_conv_7 (Conv2D)         (None, None, None, 1 294912      re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_3_norm_7 (BatchNormalizat (None, None, None, 1 512         block_3_conv_7[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, None, None, 1 0           block_3_norm_7[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block_3_conv_8 (Conv2D)         (None, None, None, 2 294912      re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_3_norm_8 (BatchNormalizat (None, None, None, 2 1024        block_3_conv_8[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 1 16384       re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, None, None, 2 0           block_3_norm_8[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 3 0           conv2d_1[0][0]                   \n",
            "                                                                 re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 3 0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block_4_conv_10 (Conv2D)        (None, None, None, 1 442368      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_norm_10 (BatchNormaliza (None, None, None, 1 512         block_4_conv_10[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, None, None, 1 0           block_4_norm_10[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_conv_11 (Conv2D)        (None, None, None, 2 294912      re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_4_norm_11 (BatchNormaliza (None, None, None, 2 1024        block_4_conv_11[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, None, None, 2 0           block_4_norm_11[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_4_conv_12 (Conv2D)        (None, None, None, 5 1179648     re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_4_norm_12 (BatchNormaliza (None, None, None, 5 2048        block_4_conv_12[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, None, None, 5 0           block_4_norm_12[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_conv_14 (Conv2D)        (None, None, None, 2 1179648     re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block_5_norm_14 (BatchNormaliza (None, None, None, 2 1024        block_5_conv_14[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, None, None, 2 0           block_5_norm_14[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_conv_15 (Conv2D)        (None, None, None, 5 1179648     re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_5_norm_15 (BatchNormaliza (None, None, None, 5 2048        block_5_conv_15[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, None, None, 5 0           block_5_norm_15[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_5_conv_16 (Conv2D)        (None, None, None, 1 4718592     re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_5_norm_16 (BatchNormaliza (None, None, None, 1 4096        block_5_conv_16[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, None, None, 1 0           block_5_norm_16[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_6_conv_18 (Conv2D)        (None, None, None, 1 1179648     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_6_norm_18 (BatchNormaliza (None, None, None, 1 512         block_6_conv_18[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, None, None, 1 0           block_6_norm_18[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_6_conv_19 (Conv2D)        (None, None, None, 2 294912      re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_6_norm_19 (BatchNormaliza (None, None, None, 2 1024        block_6_conv_19[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, None, None, 2 0           block_6_norm_19[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block_6_conv_20 (Conv2D)        (None, None, None, 5 1179648     re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "block_6_norm_20 (BatchNormaliza (None, None, None, 5 2048        block_6_conv_20[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, None, None, 5 0           block_6_norm_20[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 5 0           re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 2 102400      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 200)          0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 200)          0           global_average_pooling2d_1[0][0] \n",
            "==================================================================================================\n",
            "Total params: 12,893,632\n",
            "Trainable params: 12,884,544\n",
            "Non-trainable params: 9,088\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#mount drive \\nfrom google.colab import drive\\ndrive.mount(\\'/gdrive\\')\\nfrom keras.utils import plot_model\\nplot_model(model, to_file=\"/gdrive/My Drive/EIP3/session3/Tiny_ImgNetReLU_Data_Aug_Model.png\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9YGlSNIN-iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7ZWpfCPsdFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0DeW1XMwahJ",
        "colab_type": "code",
        "outputId": "67535abe-f91c-4aaa-a858-a8ac6614d96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "#!cp '/gdrive/My Drive/EIP3/session4/tiny-imagenet-200.zip' tiny-imagenet-200.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-07 03:45:29--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip’\n",
            "\n",
            "tiny-imagenet-200.z 100%[===================>] 236.61M  19.5MB/s    in 15s     \n",
            "\n",
            "2019-04-07 03:45:45 (15.5 MB/s) - ‘tiny-imagenet-200.zip’ saved [248100043/248100043]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAX1xwdHwhn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq 'tiny-imagenet-200.zip'\n",
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVZvHOBTwaen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
        "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRHnH907wtdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Augmentaion parameters as required.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,horizontal_flip=True)\n",
        "\"\"\"\n",
        "ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CMaBGplypsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=256\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQn-yiPe5cNG",
        "colab_type": "code",
        "outputId": "a64600c3-d34b-4f03-d8e4-ead46ae2b896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(32, 32), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eEXFrGi5ecH",
        "colab_type": "code",
        "outputId": "0c07ce5c-9099-4acf-c657-57404f160197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(32, 32),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjr_hGIsxR4c",
        "colab_type": "code",
        "outputId": "9a02d106-d5fe-4a6f-aeaa-fbbfaab92b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=25, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/25\n",
            "390/390 [==============================] - 565s 1s/step - loss: 4.7744 - acc: 0.0444 - val_loss: 5.2868 - val_acc: 0.0489\n",
            "Epoch 2/25\n",
            "390/390 [==============================] - 553s 1s/step - loss: 4.0482 - acc: 0.1202 - val_loss: 4.3808 - val_acc: 0.1100\n",
            "Epoch 3/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 3.5872 - acc: 0.1908 - val_loss: 4.4812 - val_acc: 0.1282\n",
            "Epoch 4/25\n",
            "390/390 [==============================] - 545s 1s/step - loss: 3.2662 - acc: 0.2492 - val_loss: 4.1739 - val_acc: 0.1453\n",
            "Epoch 5/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 3.0122 - acc: 0.2970 - val_loss: 3.3904 - val_acc: 0.2365\n",
            "Epoch 6/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 2.8045 - acc: 0.3339 - val_loss: 3.2310 - val_acc: 0.2704\n",
            "Epoch 7/25\n",
            "390/390 [==============================] - 545s 1s/step - loss: 2.6289 - acc: 0.3703 - val_loss: 3.1632 - val_acc: 0.2834\n",
            "Epoch 8/25\n",
            "390/390 [==============================] - 545s 1s/step - loss: 2.4727 - acc: 0.4010 - val_loss: 3.1590 - val_acc: 0.2848\n",
            "Epoch 9/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 2.3379 - acc: 0.4291 - val_loss: 2.9978 - val_acc: 0.3188\n",
            "Epoch 10/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 2.2088 - acc: 0.4556 - val_loss: 2.7714 - val_acc: 0.3528\n",
            "Epoch 11/25\n",
            "390/390 [==============================] - 544s 1s/step - loss: 2.0915 - acc: 0.4802 - val_loss: 2.6813 - val_acc: 0.3705\n",
            "Epoch 12/25\n",
            "390/390 [==============================] - 546s 1s/step - loss: 1.9782 - acc: 0.5019 - val_loss: 2.6640 - val_acc: 0.3763\n",
            "Epoch 13/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.8708 - acc: 0.5249 - val_loss: 2.8438 - val_acc: 0.3598\n",
            "Epoch 14/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.7718 - acc: 0.5469 - val_loss: 2.6629 - val_acc: 0.3913\n",
            "Epoch 15/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.6717 - acc: 0.5694 - val_loss: 2.5919 - val_acc: 0.4049\n",
            "Epoch 16/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.5682 - acc: 0.5926 - val_loss: 2.6505 - val_acc: 0.3919\n",
            "Epoch 17/25\n",
            "390/390 [==============================] - 547s 1s/step - loss: 1.4736 - acc: 0.6151 - val_loss: 2.5502 - val_acc: 0.4122\n",
            "Epoch 18/25\n",
            "390/390 [==============================] - 547s 1s/step - loss: 1.3809 - acc: 0.6360 - val_loss: 2.7138 - val_acc: 0.3999\n",
            "Epoch 19/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.2863 - acc: 0.6575 - val_loss: 2.6966 - val_acc: 0.3884\n",
            "Epoch 20/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 1.1952 - acc: 0.6800 - val_loss: 2.7612 - val_acc: 0.4020\n",
            "Epoch 21/25\n",
            "390/390 [==============================] - 549s 1s/step - loss: 1.1000 - acc: 0.7031 - val_loss: 2.7455 - val_acc: 0.4067\n",
            "Epoch 22/25\n",
            "390/390 [==============================] - 549s 1s/step - loss: 1.0111 - acc: 0.7246 - val_loss: 2.9865 - val_acc: 0.3862\n",
            "Epoch 23/25\n",
            "390/390 [==============================] - 548s 1s/step - loss: 0.9193 - acc: 0.7455 - val_loss: 2.6854 - val_acc: 0.4265\n",
            "Epoch 24/25\n",
            "390/390 [==============================] - 547s 1s/step - loss: 0.8356 - acc: 0.7693 - val_loss: 2.8373 - val_acc: 0.4113\n",
            "Epoch 25/25\n",
            "390/390 [==============================] - 547s 1s/step - loss: 0.7552 - acc: 0.7906 - val_loss: 2.9558 - val_acc: 0.4122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f1b04a128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQCKgz9Ep4_3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wElcL8NTt2uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch25.h5\")\n",
        "model.save_weights(\"/gdrive/My Drive/EIP3/session4/model_weights_custom3_tiny_imgnet_epoch25.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uABpTba_Hra6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch25.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx1ou1QsG0sT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=10*100000//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iNFqSxmITYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.0001, max_lr=0.0005,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrJejgWXI09o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0lqBzElI_Lx",
        "colab_type": "code",
        "outputId": "d788cfb1-bc4a-4094-ef75-2396e0b39a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSJHfUrUJLgU",
        "colab_type": "code",
        "outputId": "9fc73f57-b37e-4f78-c4fa-c2f511c61df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQSclenGhQ3",
        "colab_type": "code",
        "outputId": "ffd444fc-2ff5-423f-d739-efd8b93495e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2204s 2s/step - loss: 1.9122 - acc: 0.5149 - val_loss: 2.1302 - val_acc: 0.4823\n",
            "Epoch 2/5\n",
            "1041/1041 [==============================] - 2193s 2s/step - loss: 1.6017 - acc: 0.5872 - val_loss: 2.0880 - val_acc: 0.4913\n",
            "Epoch 3/5\n",
            "1041/1041 [==============================] - 2180s 2s/step - loss: 1.4612 - acc: 0.6209 - val_loss: 2.0512 - val_acc: 0.5037\n",
            "Epoch 4/5\n",
            "1041/1041 [==============================] - 2175s 2s/step - loss: 1.3532 - acc: 0.6470 - val_loss: 1.9841 - val_acc: 0.5175\n",
            "Epoch 5/5\n",
            "1041/1041 [==============================] - 2177s 2s/step - loss: 1.2551 - acc: 0.6704 - val_loss: 2.0383 - val_acc: 0.5095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e972f0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8oWXua4JY4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch30.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTFo77URZaOd",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 30 \n",
        "trained on 32x32 size with horizontal flip for 25 epochs and then on 64x64 size with no augmentation.\n",
        "max validation accuracy is 51.75 at the 29th epoch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqTpgCORZVZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################end of 30 epochs ##########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRPerhEGYihu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch30.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w7u4pDeYdgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=10*100000//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yho--V50ZFHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clr = CyclicLR(base_lr=0.00005, max_lr=0.0005,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFPAp-NgeKLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6zVdlVGeOvy",
        "colab_type": "code",
        "outputId": "50764dec-6f4b-4380-c8f0-34cd2474483f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkfPxRE5eS6V",
        "colab_type": "code",
        "outputId": "d30bba87-86dd-4956-a859-d3e86d5d32e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bwH6CeUeXY0",
        "colab_type": "code",
        "outputId": "e63aaa8e-50de-4382-f756-7ac7de2e2d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2218s 2s/step - loss: 1.1448 - acc: 0.6962 - val_loss: 2.1107 - val_acc: 0.4999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a64196da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MYuH6INeaiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch31.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wEtEvFneb6B",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 31"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJRtjaasefZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################end of epoch 31 ###############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWWRJafjX_Sd",
        "colab_type": "code",
        "outputId": "f68599df-e9bc-4df4-d25a-174306a02491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2212s 2s/step - loss: 1.0677 - acc: 0.7155 - val_loss: 2.0446 - val_acc: 0.5110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a46edee80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmJmhxugYEFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch32.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xap2VDxYHYV",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUCo1m3IYKZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########### end of epoch 32 #########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSE5PASXYWx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch32.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVhOQCHuiBfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps_for_clr=6*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00005, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mKk10q3Y-eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SkulrFsgoh1",
        "colab_type": "code",
        "outputId": "1b8ad5ac-8c68-4d70-cc8d-39fb8a77a426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2223s 2s/step - loss: 0.8019 - acc: 0.7993 - val_loss: 1.9457 - val_acc: 0.5288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9a61fc34e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euM8u5VMgoxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch33.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzMvs3_3gzgL",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 33"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP_UAJnug2kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### end of epoch 33 #########"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqG2iSBtZiAQ",
        "colab_type": "code",
        "outputId": "f5d2efeb-15d5-4de7-a9bc-44869e8413cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        }
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch33.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cHp-3Z-YgPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=256\n",
        "img_size=32\n",
        "num_steps_for_clr=10*100000//batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d-eB8YBYu7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,zoom_range=[0.7,1.7])\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL8I4mRoZH5a",
        "colab_type": "code",
        "outputId": "5ab3c3bd-a0ae-4d42-9cf9-065740c7ad97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNF9G3SDZM8Z",
        "colab_type": "code",
        "outputId": "fdeb64c4-71a6-4b21-dc89-da8a901b430f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bE7obYDYETk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00005, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyCggYQeYOfy",
        "colab_type": "code",
        "outputId": "3202f7ef-78cf-4c37-9f8c-527eab233704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "390/390 [==============================] - 587s 2s/step - loss: 2.9690 - acc: 0.4123 - val_loss: 3.6551 - val_acc: 0.3807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9e3fb37320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J06auoesYRMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch34.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJsGnwtaOK2",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 34 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUMrMSZQaQgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################## end of epoch 34 - applied zoom augmentation on 32 x 32 images #####################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHB4zfN0eOLv",
        "colab_type": "code",
        "outputId": "0d7ad572-7d88-4b82-eaeb-8d1b5bdd5fb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "390/390 [==============================] - 577s 1s/step - loss: 2.1236 - acc: 0.4891 - val_loss: 3.2498 - val_acc: 0.3787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dc6939cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GliJNvGgh6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch35.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md0v_B-Ugk67",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 35 - trained on 32x32 images with zoom augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40JUWr_GgrVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### end of epoch 35 ############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llSCQ3Rzgvp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.01,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMflNaCPhbrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,zoom_range=[0.3,1.20])\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9f-tf0ompTU",
        "colab_type": "code",
        "outputId": "cc5a3806-0e6a-4d83-f6d8-3684801b375d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGgJcuACm-F2",
        "colab_type": "code",
        "outputId": "71e4a901-d183-4d1a-d43b-1b3d06158381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xltY5l_nC-g",
        "colab_type": "code",
        "outputId": "d4ddf840-af1f-43f2-9fdb-9b975518b10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2280s 2s/step - loss: 2.6883 - acc: 0.3729 - val_loss: 4.0706 - val_acc: 0.2537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dcc5eb438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t55A4quRnHNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch36.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBqXzo_Dwpze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4hPb5V4nLGR",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 36 . trained 64x64 images with zoom augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjt_ZFgunYVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############end of epoch 36 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK3SbI--wfaY",
        "colab_type": "code",
        "outputId": "ad2e0ad8-ecfd-47d0-9425-833da96fd09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2290s 2s/step - loss: 2.8008 - acc: 0.3478 - val_loss: 4.3192 - val_acc: 0.1904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dc6939630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP52ZNFOwqmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch37.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plVWa2pcxCAY",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 37 . trained 64 x64 image with zoom augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YcFaQY6xJpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### end of epoch 37 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6rYxCPwxRzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=45)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7EFjwOCyGN8",
        "colab_type": "code",
        "outputId": "7d540e0c-d526-4474-8dfe-2c698177fb6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBAGrbsqyafs",
        "colab_type": "code",
        "outputId": "21f968ce-000d-4668-e326-2e0f3fa7a843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2290s 2s/step - loss: 2.5246 - acc: 0.3939 - val_loss: 5.0812 - val_acc: 0.1710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dcc5ebe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNHKSMWuydhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch38.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vryhRUDCykBo",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 38 . trained 64 x64 images with rotation augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mydILo9xyrQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#end of epoch 38 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdz35rQISbU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.01,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjDoKK7GR-oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BapbciDtSDZU",
        "colab_type": "code",
        "outputId": "98c7409f-082e-48e9-8d58-55b7b1757f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWGtTMqwSSyU",
        "colab_type": "code",
        "outputId": "02fd221c-251b-4d94-fd54-08c01a96fa87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1V-qThSIMb",
        "colab_type": "code",
        "outputId": "00c0cba7-a60b-4c11-bd9e-a57d43168ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdB4VJISlP2",
        "colab_type": "code",
        "outputId": "a5fd285a-d3f6-442b-edf7-b1d883d0720a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch38.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc2d6CcjSvQ3",
        "colab_type": "code",
        "outputId": "6473b993-9a60-4527-b998-d6e6b7255130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=7, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "1041/1041 [==============================] - 2290s 2s/step - loss: 1.6549 - acc: 0.5820 - val_loss: 2.1372 - val_acc: 0.4840\n",
            "Epoch 2/7\n",
            "1041/1041 [==============================] - 2272s 2s/step - loss: 1.6784 - acc: 0.5691 - val_loss: 3.6941 - val_acc: 0.2827\n",
            "Epoch 3/7\n",
            "1041/1041 [==============================] - 2270s 2s/step - loss: 1.7964 - acc: 0.5424 - val_loss: 3.0474 - val_acc: 0.3337\n",
            "Epoch 4/7\n",
            "1041/1041 [==============================] - 2271s 2s/step - loss: 1.8037 - acc: 0.5404 - val_loss: 2.6646 - val_acc: 0.3986\n",
            "Epoch 5/7\n",
            "1041/1041 [==============================] - 2272s 2s/step - loss: 1.7580 - acc: 0.5524 - val_loss: 3.8331 - val_acc: 0.2858\n",
            "Epoch 6/7\n",
            "1041/1041 [==============================] - 2272s 2s/step - loss: 1.6991 - acc: 0.5641 - val_loss: 3.6634 - val_acc: 0.3055\n",
            "Epoch 7/7\n",
            "1041/1041 [==============================] - 2278s 2s/step - loss: 1.6310 - acc: 0.5783 - val_loss: 2.7143 - val_acc: 0.4101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9dcc5ebb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0WbBdizS8Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch45.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQnstc3cTBWv",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 45 . trained 7 epochs on 64x64 images with no augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWMnIyBUTLXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### end of epoch 45"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds9MtAwSIbln",
        "colab_type": "code",
        "outputId": "76ec3680-4bcf-4270-acb1-c27cc3d2b398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knNeXpE0IGQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch45.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XDhP5z7zEWE",
        "colab_type": "code",
        "outputId": "136e34cd-f342-4a51-ab4a-148f565dbca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2277s 2s/step - loss: 1.1814 - acc: 0.6922 - val_loss: 1.7539 - val_acc: 0.5690\n",
            "Epoch 2/5\n",
            "1041/1041 [==============================] - 2269s 2s/step - loss: 0.9052 - acc: 0.7638 - val_loss: 1.6895 - val_acc: 0.5836\n",
            "Epoch 3/5\n",
            "1041/1041 [==============================] - 2254s 2s/step - loss: 0.7664 - acc: 0.7968 - val_loss: 1.7154 - val_acc: 0.5898\n",
            "Epoch 4/5\n",
            "1041/1041 [==============================] - 2245s 2s/step - loss: 0.6594 - acc: 0.8243 - val_loss: 1.7283 - val_acc: 0.5925\n",
            "Epoch 5/5\n",
            "1041/1041 [==============================] - 2228s 2s/step - loss: 0.5617 - acc: 0.8500 - val_loss: 1.7680 - val_acc: 0.5927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff099251d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxvFAz77zceT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch50.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhTCvtpziGD",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 50 .trained for 5 epochs with 64x64 images -no augmentation .**Max val accuracy reached at epoch 50 - 59.27 **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQY8CbOzsxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## end of epoch 50 -val accuracy 59.27  ############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Ly8hAM1dwi",
        "colab_type": "code",
        "outputId": "7e2fd5e9-7150-46e8-d624-0b9215775801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "1041/1041 [==============================] - 2219s 2s/step - loss: 0.4692 - acc: 0.8749 - val_loss: 1.8967 - val_acc: 0.5856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff09873c198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auJ90v9M1m7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch51.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROcrDx2CBBVO",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 51 .val accuracy came down from 59.27 to 58.56 . Add more augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYRXsjddAyih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### end of epoch 51 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE3eS1KCCcB_",
        "colab_type": "code",
        "outputId": "4bd876ff-afa4-49aa-aea1-400e9f0c7770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=256\n",
        "img_size=32\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=15.0)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTZds0IhC4tl",
        "colab_type": "code",
        "outputId": "562564c6-f161-48ca-e46e-98a79c5e0b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 579s 1s/step - loss: 3.4634 - acc: 0.4235 - val_loss: 3.8690 - val_acc: 0.3945\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 571s 1s/step - loss: 2.5293 - acc: 0.4770 - val_loss: 3.0713 - val_acc: 0.4155\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 561s 1s/step - loss: 2.0374 - acc: 0.5073 - val_loss: 2.5829 - val_acc: 0.4391\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 563s 1s/step - loss: 1.8284 - acc: 0.5383 - val_loss: 2.4900 - val_acc: 0.4488\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 563s 1s/step - loss: 1.6948 - acc: 0.5651 - val_loss: 2.4112 - val_acc: 0.4609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff09099f0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F--2hqCXES2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch56.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhES32KrEb9s",
        "colab_type": "code",
        "outputId": "858b3670-9331-4c5a-969d-71c0a6371665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 564s 1s/step - loss: 1.5773 - acc: 0.5896 - val_loss: 2.3791 - val_acc: 0.4656\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 563s 1s/step - loss: 1.4792 - acc: 0.6128 - val_loss: 2.3926 - val_acc: 0.4659\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 562s 1s/step - loss: 1.3695 - acc: 0.6376 - val_loss: 2.3962 - val_acc: 0.4722\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 563s 1s/step - loss: 1.2582 - acc: 0.6628 - val_loss: 2.3626 - val_acc: 0.4837\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 563s 1s/step - loss: 1.1411 - acc: 0.6910 - val_loss: 2.4223 - val_acc: 0.4848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff09099f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnBji3BAEfZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch61.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfc8u0MpZncA",
        "colab_type": "code",
        "outputId": "7c7c2b1a-de67-4063-d82c-3b1a87ac754d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=1, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "390/390 [==============================] - 557s 1s/step - loss: 1.0322 - acc: 0.7186 - val_loss: 2.4103 - val_acc: 0.4906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff099251c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vUAdlPScL2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch62.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ghuO_M7cRj4",
        "colab_type": "code",
        "outputId": "b082ce0d-1f44-4519-9f42-23e5a7507ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=3, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 564s 1s/step - loss: 0.9463 - acc: 0.7416 - val_loss: 2.4224 - val_acc: 0.4948\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 563s 1s/step - loss: 0.8695 - acc: 0.7620 - val_loss: 2.5247 - val_acc: 0.4875\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 563s 1s/step - loss: 0.8078 - acc: 0.7795 - val_loss: 2.5055 - val_acc: 0.4948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0b0085320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pH6beeTcVNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch65.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8TAoF_RVqqx",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 65 . Trained epochs 52-65 on 32x32 images with Shear transform augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xNPldRmV6tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######End of epoch 65 #######"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP9sE366xtIf",
        "colab_type": "code",
        "outputId": "63df2a96-98a3-4a20-fc68-5a341c0482e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=15.0)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QWe1Pqqx541",
        "colab_type": "code",
        "outputId": "172d9aa9-6f32-4bce-b855-84d8b2d32f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2258s 2s/step - loss: 1.1332 - acc: 0.6964 - val_loss: 1.8350 - val_acc: 0.5598\n",
            "Epoch 2/5\n",
            "1041/1041 [==============================] - 2254s 2s/step - loss: 0.7637 - acc: 0.7931 - val_loss: 1.7712 - val_acc: 0.5883\n",
            "Epoch 3/5\n",
            "1041/1041 [==============================] - 2253s 2s/step - loss: 0.6350 - acc: 0.8277 - val_loss: 1.8099 - val_acc: 0.5891\n",
            "Epoch 4/5\n",
            "1041/1041 [==============================] - 2254s 2s/step - loss: 0.5614 - acc: 0.8458 - val_loss: 1.8645 - val_acc: 0.5863\n",
            "Epoch 5/5\n",
            "1041/1041 [==============================] - 2252s 2s/step - loss: 0.5029 - acc: 0.8616 - val_loss: 1.8902 - val_acc: 0.5877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0909164e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V8EGptpWHzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch70.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnrN0_QSWxeC",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 70. Trained 5 epochs with 64x64 images and augmentation shear transform .val accuracy went to 58.91 at epoch 68 .Max val accuracy so far remains 59.27 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EudKCrgaWv5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### end of epoch 70. 4 augmentations so far : horizontal_flip, zoom, rotation, shear ######"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPTVKwDWK-M",
        "colab_type": "code",
        "outputId": "9b4ab639-77a5-494e-9d6f-b4428007a1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "### do 5 epochs without augmentation at 64x64 size\n",
        "\n",
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Q3ItWIZO08",
        "colab_type": "code",
        "outputId": "875ffc12-04f6-4bc2-fd47-d591f9b0283c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2256s 2s/step - loss: 0.2862 - acc: 0.9332 - val_loss: 1.7454 - val_acc: 0.6168\n",
            "Epoch 2/5\n",
            " 977/1041 [===========================>..] - ETA: 2:14 - loss: 0.2564 - acc: 0.9413"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om7fcB2vZa70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch75.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfLXTEVTZdcQ",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 71 (Runtime disconnected after epoch 71) trained on 64x64 images with no augmentation for this epoch . \n",
        "\n",
        "**Max validation accuracy at the end of epoch 71 is 61.68**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1O3zBAiZjZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######### end of epoch 71 ######"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USG_KYL2uoSd",
        "colab_type": "code",
        "outputId": "94472486-dd49-490d-f040-a005753edf6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "### load last saved model and do 4 more epochs without augmentation at 64x64 size\n",
        "\n",
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AHznLUovFMw",
        "colab_type": "code",
        "outputId": "17c578a4-0513-4074-b9f5-e49f4af3b353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch70.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YU5OCAefxZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "  \n",
        "chkpoint_model=ModelCheckpoint(\"/gdrive/My Drive/EIP3/session4/model_custom_3_tiny_imgnet_best.h5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='max')\n",
        "chkpoint_weights=ModelCheckpoint(\"/gdrive/My Drive/EIP3/session4/model_weights_custom_3_tiny_imgnet_best.h5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkWtHf-bu-U2",
        "colab_type": "code",
        "outputId": "d568e7bc-23c5-4703-9a3e-b1c9e940b1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=4, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr,chkpoint_model,chkpoint_weights],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1041/1041 [==============================] - 2339s 2s/step - loss: 0.2862 - acc: 0.9332 - val_loss: 1.7453 - val_acc: 0.6168\n",
            "Epoch 2/4\n",
            "1041/1041 [==============================] - 2329s 2s/step - loss: 0.2557 - acc: 0.9417 - val_loss: 1.7860 - val_acc: 0.6120\n",
            "Epoch 3/4\n",
            "1041/1041 [==============================] - 2305s 2s/step - loss: 0.2269 - acc: 0.9496 - val_loss: 1.8813 - val_acc: 0.6013\n",
            "Epoch 4/4\n",
            "1041/1041 [==============================] - 2299s 2s/step - loss: 0.1895 - acc: 0.9600 - val_loss: 1.9519 - val_acc: 0.5987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9eeb64e3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7whQ3N7veKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch75.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1F1utCJvgWV",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 75 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1YJ1WDOv2ki",
        "colab_type": "code",
        "outputId": "764f1ee8-ba5d-4956-a306-f3322521b550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "### load last saved model and do 4 more epochs without augmentation at 32x32 size\n",
        "\n",
        "batch_size=256\n",
        "img_size=32\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True, width_shift_range=0.4, height_shift_range=0.4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuTCDjy1wewE",
        "colab_type": "code",
        "outputId": "a688c9f9-0a67-4651-93ea-7ed216da0656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr,chkpoint_model,chkpoint_weights],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "390/390 [==============================] - 592s 2s/step - loss: 6.6115 - acc: 0.2269 - val_loss: 5.4504 - val_acc: 0.3733\n",
            "Epoch 2/5\n",
            "390/390 [==============================] - 585s 2s/step - loss: 3.9731 - acc: 0.2536 - val_loss: 2.9669 - val_acc: 0.3905\n",
            "Epoch 3/5\n",
            "390/390 [==============================] - 575s 1s/step - loss: 3.2103 - acc: 0.2865 - val_loss: 2.6873 - val_acc: 0.4174\n",
            "Epoch 4/5\n",
            "390/390 [==============================] - 575s 1s/step - loss: 2.9941 - acc: 0.3172 - val_loss: 2.6599 - val_acc: 0.4292\n",
            "Epoch 5/5\n",
            "390/390 [==============================] - 576s 1s/step - loss: 2.8528 - acc: 0.3385 - val_loss: 2.6190 - val_acc: 0.4298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ee77cfa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtahPJIJwteN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch80.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4T-8WmnwxC3",
        "colab_type": "text"
      },
      "source": [
        "End of epoch 80 . added 3 more augmentations v_flip, width_shift and height_shift "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9C5p5Qcy-ad",
        "colab_type": "code",
        "outputId": "f07d4a7f-671f-4a64-9ef6-30c496f7e64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True, width_shift_range=0.4, height_shift_range=0.4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_aXTJw4zJTY",
        "colab_type": "code",
        "outputId": "034bd31d-8599-4e35-cb1c-2b82136dcf9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr,chkpoint_model,chkpoint_weights],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2297s 2s/step - loss: 2.3523 - acc: 0.4318 - val_loss: 2.1165 - val_acc: 0.5232\n",
            "Epoch 2/5\n",
            "1041/1041 [==============================] - 2293s 2s/step - loss: 2.0115 - acc: 0.5019 - val_loss: 2.0905 - val_acc: 0.5513\n",
            "Epoch 3/5\n",
            "1041/1041 [==============================] - 2296s 2s/step - loss: 1.9044 - acc: 0.5264 - val_loss: 2.1370 - val_acc: 0.5551\n",
            "Epoch 4/5\n",
            "1041/1041 [==============================] - 2301s 2s/step - loss: 1.8454 - acc: 0.5377 - val_loss: 2.1975 - val_acc: 0.5433\n",
            "Epoch 5/5\n",
            "1041/1041 [==============================] - 2311s 2s/step - loss: 1.7830 - acc: 0.5499 - val_loss: 2.2362 - val_acc: 0.5505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9eeac00630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIq6YJ7Dzcwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch85.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgyyRFpZyguC",
        "colab_type": "text"
      },
      "source": [
        "end of epoch 85 .Augmentations applied so far -horizontal flip, zoom, rotation, shear , vertical flip , width shift , height shift "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emljW_h_yz1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############end of epoch 85 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qk-r8IKy28w",
        "colab_type": "code",
        "outputId": "22e4515f-d5c7-4b74-9af8-9b2c17643358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn9RCo0vy_3F",
        "colab_type": "code",
        "outputId": "32e94ab4-5d4e-49bd-a4c2-52d8e0e6f01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=5, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr,chkpoint_model,chkpoint_weights],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1041/1041 [==============================] - 2318s 2s/step - loss: 0.6243 - acc: 0.8340 - val_loss: 1.7285 - val_acc: 0.6099\n",
            "Epoch 2/5\n",
            "1041/1041 [==============================] - 2314s 2s/step - loss: 0.3339 - acc: 0.9164 - val_loss: 1.7490 - val_acc: 0.6172\n",
            "Epoch 3/5\n",
            " 392/1041 [==========>...................] - ETA: 23:20 - loss: 0.2402 - acc: 0.9475"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ0zh3PFzQgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch90.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmTlYjx7TOTB",
        "colab_type": "text"
      },
      "source": [
        "Session ended after epoch 87 . **max val accuracy was 61.72 at the end of epoch 87 ** . \n",
        "Load best model saved via call back and continue training for another 8 epochs to see if val accuracy improves "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGuTQnllT8PY",
        "colab_type": "code",
        "outputId": "67baf623-ba20-4727-9355-fb77cfad0255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom_3_tiny_imgnet_best.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJGSniVTUOMn",
        "colab_type": "code",
        "outputId": "4f0addd6-702d-42f6-d793-ac09b2810c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=96\n",
        "img_size=64\n",
        "num_steps_for_clr=8*100000//batch_size\n",
        "clr = CyclicLR(base_lr=0.00001, max_lr=0.001,\n",
        "                                step_size=num_steps_for_clr, mode='triangular2')\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( r'./tiny-imagenet-200/train/', target_size=(img_size,img_size), color_mode='rgb', \n",
        "                                                    batch_size=batch_size, class_mode='categorical', shuffle=True, seed=42)\n",
        "\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=True, seed=42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu6QMdQlmtje",
        "colab_type": "code",
        "outputId": "07e22a04-f2db-425e-8ba5-a60c48d17c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "model.fit_generator(train_generator, epochs=8, \n",
        "                        steps_per_epoch=100000//batch_size, \n",
        "                    validation_steps=10000//batch_size, \n",
        "                    validation_data=validation_generator,shuffle=True,callbacks=[clr,chkpoint_model,chkpoint_weights],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "1041/1041 [==============================] - 2220s 2s/step - loss: 0.2366 - acc: 0.9494 - val_loss: 1.7570 - val_acc: 0.6188\n",
            "Epoch 2/8\n",
            "1041/1041 [==============================] - 2207s 2s/step - loss: 0.1980 - acc: 0.9611 - val_loss: 1.8087 - val_acc: 0.6174\n",
            "Epoch 3/8\n",
            "1041/1041 [==============================] - 2192s 2s/step - loss: 0.1569 - acc: 0.9729 - val_loss: 1.9035 - val_acc: 0.6101\n",
            "Epoch 4/8\n",
            "1041/1041 [==============================] - 2197s 2s/step - loss: 0.1114 - acc: 0.9845 - val_loss: 2.0051 - val_acc: 0.6018\n",
            "Epoch 5/8\n",
            "1041/1041 [==============================] - 2205s 2s/step - loss: 0.0912 - acc: 0.9862 - val_loss: 2.1050 - val_acc: 0.6013\n",
            "Epoch 6/8\n",
            "  81/1041 [=>............................] - ETA: 32:47 - loss: 0.0715 - acc: 0.9901"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZeXxFgCmzGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/gdrive/My Drive/EIP3/session4/model_custom3_tiny_imgnet_epoch95.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jALJipOCw6P",
        "colab_type": "text"
      },
      "source": [
        "session disconnected after epoch 92. **By now the model has clearly overfit . Max validation accuracy was 61.88**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RppGkStFDJ9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load best model (best val accuracy was 61.88) and evaluate to check score #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_93My76rYv",
        "colab_type": "code",
        "outputId": "86cf99e3-8cf2-4cb0-a9c7-88cdb79454d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "model=load_model(\"/gdrive/My Drive/EIP3/session4/model_custom_3_tiny_imgnet_best.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CVtF0Mk7Aho",
        "colab_type": "code",
        "outputId": "6be3aee5-3240-4975-f8d5-7c4465e6437a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=100\n",
        "img_size=64\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = valid_datagen.flow_from_dataframe(val_data, directory='./tiny-imagenet-200/val/images/', x_col='File', y_col='Class', target_size=(img_size,img_size),\n",
        "                                                    color_mode='rgb', class_mode='categorical', batch_size=batch_size, shuffle=False, seed=42)\n",
        "\n",
        "\n",
        "score=model.evaluate_generator(generator=validation_generator,steps=10000//batch_size)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10000 images belonging to 200 classes.\n",
            "[1.7567966926097869, 0.6187000000476837]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUh4izpDZA0",
        "colab_type": "text"
      },
      "source": [
        "**model.evaluate gives an accuracy of 61.87 which is pretty close to max validation accuracy 0f 61.88 ** \n",
        "\n",
        "Identifying and extra training for hard to predict classes should probably have been done at the 45-50 epoch mark where it was already starting to overfit training samples . Perhaps running more epochs with augmented sets would have yielded better results . Will have to go back to a model at around 40 epoch mark and try these improvement strategies"
      ]
    }
  ]
}